# Table of Contents
1. [Project Overview](#project-overview)
2. [References](#references)

# Project Overview
This project focuses on the desigining a simple NN from scratch , defining training and validations logics, implmentating SGD, softmax, nll and other basic algorithms in machine learning. It includes 4 different notebooks. They are:
1. makemore.ipynb deals with simple implementation of NN including forward and backward pass, nll loss and basic algorithms and training related things.
2. makemore_MLP.ipynb deals withn implementation of multilayer perceptrons, softmax and related issues,embeddings and some visualizations.
3. makemore_activation_BN.ipynb explores the initialization techiniques, covariance shifts and how appropriate initialization of weights and biases effects training process. Moreover, it implements BatchNormalization and talk about its regularization effects.
4. backprop.ipynb focuses on backward pass for model training and implemets backpropagation from scratch.

# References

This entrie repository is inspired from Andrej Karpathy's makemore series.
https://github.com/karpathy/makemore